{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import io\n",
    "import numpy as np\n",
    "import torch\n",
    "import trimesh\n",
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from depth_pro import create_model_and_transforms, load_rgb\n",
    "from pycocotools import mask as maskUtils\n",
    "import open3d as o3d\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Camera intrinsic parameters\n",
    "fx = 3098.0475\n",
    "fy = 3097.4233\n",
    "cx = 2031.6249\n",
    "cy = 1524.7746\n",
    "\n",
    "# Camera extrinsic parameters\n",
    "R = np.array([\n",
    "    [0.965286851297566, 0.248307782214057, -0.0810218489295801],\n",
    "    [-0.157358887774226, 0.800448714153273, 0.578377071164504],\n",
    "    [0.208469362618323, -0.545550273854123, 0.811736055345087]\n",
    "])\n",
    "T = np.array([-101.197833337719, -31.2983198623872, 356.795325964250]).reshape(3, 1)\n",
    "\n",
    "# Initialize segmentation and depth models\n",
    "\n",
    "seg_model = YOLO('yolo11x-seg.pt')\n",
    "device = torch.device(\"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "depth_model, transform = create_model_and_transforms(device=device, precision=torch.half)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calibrate_camera(image_paths):\n",
    "    \"\"\"Calibrate camera using checker board images\"\"\"\n",
    "    # Checker board dimensions\n",
    "    CHECKERBOARD = (7, 10)\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "\n",
    "    # Prepare object points\n",
    "    objp = np.zeros((CHECKERBOARD[0] * CHECKERBOARD[1], 3), np.float32)\n",
    "    objp[:,:2] = np.mgrid[0:CHECKERBOARD[0], 0:CHECKERBOARD[1]].T.reshape(-1,2)\n",
    "\n",
    "    objpoints = []  # 3D points in real world space\n",
    "    imgpoints = []  # 2D points in image plane\n",
    "\n",
    "    for image_path in image_paths[:-1]:  # Process all images except the last one\n",
    "        img = cv2.imread(image_path)\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        ret, corners = cv2.findChessboardCorners(gray, CHECKERBOARD, None)\n",
    "        \n",
    "        if ret:\n",
    "            corners2 = cv2.cornerSubPix(gray, corners, (11,11), (-1,-1), criteria)\n",
    "            objpoints.append(objp)\n",
    "            imgpoints.append(corners2)\n",
    "\n",
    "    # Calibrate camera\n",
    "    ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, gray.shape[::-1], None, None)\n",
    "\n",
    "    # Get extrinsic parameters from last image\n",
    "    last_img = cv2.imread(image_paths[-1])\n",
    "    last_gray = cv2.cvtColor(last_img, cv2.COLOR_BGR2GRAY)\n",
    "    ret, corners = cv2.findChessboardCorners(last_gray, CHECKERBOARD, None)\n",
    "    \n",
    "    if ret:\n",
    "        corners2 = cv2.cornerSubPix(last_gray, corners, (11,11), (-1,-1), criteria)\n",
    "        _, rvec, tvec = cv2.solvePnP(objp, corners2, mtx, dist)\n",
    "        R, _ = cv2.Rodrigues(rvec)\n",
    "        T = tvec\n",
    "\n",
    "    return mtx, dist, R, T\n",
    "\n",
    "def get_extrinsic_params(image_path):\n",
    "    \"\"\"Get extrinsic parameters from an image using camera intrinsic parameters\"\"\"\n",
    "    # Checker board dimensions (7x10)\n",
    "    CHECKERBOARD = (7, 10)\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "    # Prepare object points\n",
    "    objp = np.zeros((CHECKERBOARD[0] * CHECKERBOARD[1], 3), np.float32)\n",
    "    objp[:,:2] = np.mgrid[0:CHECKERBOARD[0], 0:CHECKERBOARD[1]].T.reshape(-1,2)\n",
    "    # Create camera matrix from intrinsic parameters\n",
    "    camera_matrix = np.array([[fx, 0, cx],\n",
    "                             [0, fy, cy],\n",
    "                             [0, 0, 1]], dtype=np.float32)\n",
    "    \n",
    "    # Process image\n",
    "    img = cv2.imread(image_path)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    ret, corners = cv2.findChessboardCorners(gray, CHECKERBOARD, None)\n",
    "    \n",
    "    if ret:\n",
    "        corners2 = cv2.cornerSubPix(gray, corners, (11,11), (-1,-1), criteria)\n",
    "        # Assuming no distortion\n",
    "        dist_coeffs = np.zeros((4,1))\n",
    "        # Get rotation and translation vectors\n",
    "        _, rvec, tvec = cv2.solvePnP(objp, corners2, camera_matrix, dist_coeffs)\n",
    "        R, _ = cv2.Rodrigues(rvec)\n",
    "        T = tvec\n",
    "        return R, T\n",
    "    \n",
    "    return None, None\n",
    "\n",
    "def generate_cylinder_obj(radius: float, height: float):\n",
    "    \"\"\"Generate cylinder mesh object\"\"\"\n",
    "    # Create cylinder using trimesh\n",
    "    cylinder = trimesh.creation.cylinder(radius=radius, height=height, sections=32)\n",
    "    # Generate memory stream\n",
    "    obj_stream = io.BytesIO()\n",
    "    cylinder.export(obj_stream, file_type='obj')\n",
    "    # Convert BytesIO to string\n",
    "    obj_stream.seek(0)\n",
    "    return obj_stream.read().decode('utf-8')\n",
    "\n",
    "def generate_mask_COCO(image_path: str):\n",
    "    \"\"\"Generate COCO format segmentation mask\"\"\"\n",
    "    results = seg_model.predict(source=image_path, show=False)\n",
    "    result = results[0]\n",
    "    if result.masks is not None and result.boxes is not None:\n",
    "        mask = result.masks.xy[0]\n",
    "        segmentation = [float(coord) for segment in mask.tolist() for coord in segment]\n",
    "    return segmentation\n",
    "\n",
    "def generate_depthmap(image_path: str):\n",
    "    \"\"\"Generate depth map from RGB image\"\"\"\n",
    "    try:\n",
    "        image, _, f_px = load_rgb(image_path)\n",
    "    except Exception as e:\n",
    "        return np.array([])\n",
    "    prediction = depth_model.infer(transform(image), f_px=f_px)\n",
    "    depth = prediction[\"depth\"].detach().cpu().numpy().squeeze()\n",
    "    return depth\n",
    "\n",
    "def create_point_cloud(depth_map, mask):\n",
    "    \"\"\"Create point cloud from depth map and mask\"\"\"\n",
    "    # Get valid points within 90th percentile depth threshold\n",
    "    depth_threshold = np.percentile(depth_map[depth_map * mask > 0], 95)\n",
    "    valid_indices = np.where((depth_map * mask > 0) & (depth_map <= depth_threshold))\n",
    "    depths = depth_map[valid_indices]\n",
    "    xs, ys = np.meshgrid(np.arange(depth_map.shape[1]), np.arange(depth_map.shape[0]))\n",
    "\n",
    "    # Convert to camera coordinates\n",
    "    points_camera = np.vstack((\n",
    "        (xs[valid_indices] - cx) * depths / fx,\n",
    "        (ys[valid_indices] - cy) * depths / fy,\n",
    "        depths\n",
    "    ))\n",
    "    \n",
    "    # Transform to world coordinates\n",
    "    return R.T @ (points_camera - T)\n",
    "\n",
    "def cluster_points(points):\n",
    "    \"\"\"Cluster points using DBSCAN\"\"\"\n",
    "    # Project to 2D space\n",
    "    xy_dist = np.sqrt(points[0]**2 + points[1]**2)\n",
    "    points_2d = np.vstack((xy_dist, points[2])).T\n",
    "    \n",
    "    # Apply DBSCAN clustering\n",
    "    points_2d_scaled = StandardScaler().fit_transform(points_2d)\n",
    "    labels = DBSCAN(eps=0.2, min_samples=40).fit_predict(points_2d_scaled)\n",
    "    \n",
    "    return labels != -1  # Return valid points mask\n",
    "\n",
    "def generate_3d_AABB(segmentation, depth, visualization=False):\n",
    "    \"\"\"Generate 3D bounding box from segmentation and depth\"\"\"\n",
    "    # Create binary mask\n",
    "    mask = np.zeros_like(depth, dtype=np.uint8)\n",
    "    cv2.fillPoly(mask, [np.array(segmentation).reshape(-1, 2).astype(int)], 1)\n",
    "\n",
    "    # Create point cloud\n",
    "    points_world = create_point_cloud(depth, mask)\n",
    "\n",
    "    # Apply downsampling\n",
    "    sample_size = min(10000, points_world.shape[1])\n",
    "    sample_indices = np.random.choice(points_world.shape[1], size=sample_size, replace=False)\n",
    "    sampled_points = points_world[:, sample_indices]\n",
    "\n",
    "    # Remove noise using clustering\n",
    "    valid_mask = cluster_points(sampled_points)\n",
    "    valid_points = sampled_points[:, valid_mask].T\n",
    "\n",
    "    # Calculate bounding box\n",
    "    valid_cloud = o3d.geometry.PointCloud()\n",
    "    valid_cloud.points = o3d.utility.Vector3dVector(valid_points)\n",
    "    aabb = valid_cloud.get_axis_aligned_bounding_box()\n",
    "    \n",
    "    # Calculate dimensions\n",
    "    size = aabb.get_max_bound() - aabb.get_min_bound()\n",
    "    # Visualization (optional)\n",
    "    if visualization:  # Toggle visualization\n",
    "        aabb.color = (0, 1, 0)  # Green bounding box\n",
    "        valid_cloud.paint_uniform_color([1, 0, 0])  # Red points\n",
    "        o3d.visualization.draw_geometries(\n",
    "            [valid_cloud, aabb],\n",
    "            window_name=\"Clustering Result without Noise\",\n",
    "            width=800, height=600\n",
    "        )\n",
    "\n",
    "    return size\n",
    "\n",
    "def generate_3d_OBB(segmentation, depth, visualization=False):\n",
    "    \"\"\"Generate 3D bounding box from segmentation and depth\"\"\"\n",
    "    # Create binary mask\n",
    "    mask = np.zeros_like(depth, dtype=np.uint8)\n",
    "    cv2.fillPoly(mask, [np.array(segmentation).reshape(-1, 2).astype(int)], 1)\n",
    "\n",
    "    # Create point cloud\n",
    "    points_world = create_point_cloud(depth, mask)\n",
    "\n",
    "    # Apply downsampling\n",
    "    sample_size = min(10000, points_world.shape[1])\n",
    "    sample_indices = np.random.choice(points_world.shape[1], size=sample_size, replace=False)\n",
    "    sampled_points = points_world[:, sample_indices]\n",
    "\n",
    "    # Remove noise using clustering\n",
    "    valid_mask = cluster_points(sampled_points)\n",
    "    valid_points = sampled_points[:, valid_mask].T\n",
    "\n",
    "    # Calculate bounding box\n",
    "    valid_cloud = o3d.geometry.PointCloud()\n",
    "    valid_cloud.points = o3d.utility.Vector3dVector(valid_points)\n",
    "    obb = valid_cloud.get_oriented_bounding_box()\n",
    "    \n",
    "    # Calculate dimensions\n",
    "    size = obb.get_max_bound() - obb.get_min_bound()\n",
    "    # Visualization (optional)\n",
    "    if visualization:  # Toggle visualization\n",
    "        obb.color = (0, 1, 0)  # Green bounding box\n",
    "        valid_cloud.paint_uniform_color([1, 0, 0])  # Red points\n",
    "        o3d.visualization.draw_geometries(\n",
    "            [valid_cloud, obb],\n",
    "            window_name=\"Clustering Result without Noise\",\n",
    "            width=800, height=600\n",
    "        )\n",
    "\n",
    "    return size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /Users/yoonseok/Documents/Coding/Gencycle/python/assets/example6.jpg: 480x640 1 book, 1771.6ms\n",
      "Speed: 17.5ms preprocess, 1771.6ms inference, 21.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Depth map generation time:  31.166950941085815\n"
     ]
    }
   ],
   "source": [
    "R, T = get_extrinsic_params(\"assets/example6.jpg\")\n",
    "rgb_path = \"assets/example6.jpg\"\n",
    "segmentation = generate_mask_COCO(rgb_path)\n",
    "start_time = time.time()\n",
    "depth = generate_depthmap(rgb_path)\n",
    "print(\"Depth map generation time: \", time.time() - start_time)\n",
    "\n",
    "size = generate_3d_AABB(segmentation, depth, True)\n",
    "\n",
    "print(size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gencycle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
